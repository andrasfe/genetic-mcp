# Genetic MCP Configuration

# Transport mode: stdio (default) or http
GENETIC_MCP_TRANSPORT=stdio

# HTTP server settings (when GENETIC_MCP_TRANSPORT=http)
GENETIC_MCP_HOST=0.0.0.0
GENETIC_MCP_PORT=3000

# REQUIRED: Default model for idea generation
# Examples: meta-llama/llama-3.2-3b-instruct, gpt-4-turbo-preview, claude-3-opus-20240229
MODEL=meta-llama/llama-3.2-3b-instruct

# LLM API Keys (at least one required)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: Additional LLM providers
COHERE_API_KEY=
GOOGLE_API_KEY=

# Session settings
SESSION_TIMEOUT_MINUTES=60
MAX_SESSIONS_PER_CLIENT=10

# Worker settings
MAX_WORKERS_PER_SESSION=20
WORKER_TIMEOUT_SECONDS=120

# Genetic algorithm settings
DEFAULT_POPULATION_SIZE=10
DEFAULT_GENERATIONS=5
DEFAULT_MUTATION_RATE=0.1
DEFAULT_CROSSOVER_RATE=0.7
DEFAULT_ELITISM_COUNT=2

# Fitness weights (must sum to 1.0)
FITNESS_WEIGHT_RELEVANCE=0.4
FITNESS_WEIGHT_NOVELTY=0.3
FITNESS_WEIGHT_FEASIBILITY=0.3

# Embedding settings
# Options: openai, cohere, sentence-transformer, voyage, dummy
EMBEDDING_PROVIDER=cohere
# Model for the chosen provider (provider-specific defaults apply)
EMBEDDING_MODEL=embed-english-v3.0
EMBEDDING_CACHE_SIZE=10000

# Logging
GENETIC_MCP_DEBUG=false
LOG_LEVEL=INFO
LOG_FILE=genetic_mcp.log

# Security
MAX_REQUEST_SIZE_MB=10
RATE_LIMIT_REQUESTS_PER_MINUTE=60